{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pylab\n",
      "from pylab import *\n",
      "from collections import OrderedDict\n",
      "%matplotlib inline\n",
      "plt.rcParams['image.interpolation'] = 'nearest'\n",
      "plt.rcParams['image.cmap'] = 'gray'\n",
      "\n",
      "# Make sure that caffe is on the python path:\n",
      "caffe_root = '../'  # this file is expected to be in {caffe_root}/examples\n",
      "import sys\n",
      "sys.path.insert(0, caffe_root + 'python')\n",
      "import caffe\n",
      "from caffe import imagenet\n",
      "\n",
      "\n",
      "# Some function definitions\n",
      "def figsize(width,height):\n",
      "    rcParams['figure.figsize'] = (width,height)\n",
      "    \n",
      "def shownet(net, layers=False):\n",
      "    print '%-41s%-31s%s' % ('', 'acts', 'act diffs')\n",
      "    print '%-45s%-31s%s' % ('', 'params', 'param diffs')\n",
      "    for k, v in net.blobs.items():\n",
      "        if k in net.params:\n",
      "            params = net.params[k]\n",
      "            for pp, blob in enumerate(params):\n",
      "                if pp == 0:\n",
      "                    print '  ', 'P: %-5s'%k,\n",
      "                else:\n",
      "                    print ' ' * 11,\n",
      "                print '%-32s' % repr(blob.data.shape),\n",
      "                print '%-30s' % ('(%g, %g)' % (blob.data.min(), blob.data.max())),\n",
      "                print '(%g, %g)' % (blob.diff.min(), blob.diff.max())\n",
      "        print '%-5s'%k, '%-34s' % repr(v.data.shape),\n",
      "        print '%-30s' % ('(%g, %g)' % (v.data.min(), v.data.max())),\n",
      "        print '(%g, %g)' % (v.diff.min(), v.diff.max())\n",
      "\n",
      "    if layers:\n",
      "        print\n",
      "        print 'Layers:'\n",
      "        print net.complete_layers\n",
      "        \n",
      "# TODO\n",
      "### HERE 2. <see _caffe.cpp about doing BackwardPartial>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which Model to load"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_dir = '../examples/imagenet/results/140311_234854_afadfd3_priv_netbase/'\n",
      "model_def_file = '../examples/imagenet/imagenet_deploy.prototxt'\n",
      "pretrained_model = results_dir + 'caffe_imagenet_train_iter_450000'\n",
      "with open('../data/ilsvrc12/synset_words.txt') as ff:\n",
      "    labels = [line.strip() for line in ff.readlines()]\n",
      "#image_filename = caffe_root + 'examples/images/cat.jpg'\n",
      "image_filename = caffe_root + 'examples/images/lion.jpg'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Complete forward pass"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the model and show network with all activations set to 0"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = caffe.Net(model_def_file, pretrained_model)\n",
      "net.set_phase_test()\n",
      "net.set_mode_cpu()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shownet(net, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Do a Standard `Forward` from data layer through the whole network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_blob = imagenet.prepare_image(image_filename)\n",
      "output_blob = empty((10, 1000, 1, 1), dtype=np.float32)\n",
      "\n",
      "net.Forward([data_blob], [output_blob])\n",
      "figsize(12,4)\n",
      "plot(output_blob[4].flatten())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All layers of the network have data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save data for comparison later"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saved_blobs = OrderedDict()\n",
      "for name,blob in net.blobs.items():\n",
      "    #print name, blob.data.shape\n",
      "    saved_blobs[name] = blob.data.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Partial forward pass"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reload net to set all activations to 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = caffe.Net(model_def_file, pretrained_model)\n",
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pool1 = net.ForwardFrom('data', 'pool1', data_blob)\n",
      "print 'difference:', abs(saved_blobs['pool1'] - pool1).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we can see, the activations have flowed only partially through the network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Partial forward pass from middle"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, this isn't so useful, because we could have done the same thing by doing a complete forward pass and then grabbing the data from the single blob we wanted, all of which are possible with the standard interface. However, what is missing is the ability to start from specified data in the middle of the network."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = caffe.Net(model_def_file, pretrained_model)\n",
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we put in the saved value for pool1 and go forward to conv5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conv5 = net.ForwardFrom('pool1', 'conv5', saved_blobs['pool1'])\n",
      "print 'difference:', abs(saved_blobs['conv5'] - conv5).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "They don't match! This is because the conv5 does not yet include the relu, whereas when we saved the conv5 blob before, it did. If we manually apply the relu, we get the expected values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conv5_relu = maximum(0, conv5)\n",
      "print 'difference:', abs(saved_blobs['conv5'] - conv5_relu).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note the negative values in the conv5 layer. This must be because the relu is applied in place."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Alternately, we can just go to the `relu5` layer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = caffe.Net(model_def_file, pretrained_model)\n",
      "relu5 = net.ForwardFrom('pool1', 'relu5', saved_blobs['pool1'], shape_ref='conv5')\n",
      "print 'difference:', abs(saved_blobs['conv5'] - relu5).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's try going from the conv2 to conv5 layer (past the relu):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = caffe.Net(model_def_file, pretrained_model)\n",
      "relu5 = net.ForwardFrom('conv2', 'relu5', saved_blobs['conv2'], shape_ref='conv5')\n",
      "print 'difference:', abs(saved_blobs['conv5'] - relu5).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: this actually goes through the relu2 twice: the first time to produce the `saved_blobs['conv2']` that we grabbed, and the second time when we put it in to the network at conv2 en-route to relu2. This is fine, because `relu(relu(x)) == relu(x)`, but if we were using sigmoids, this would be a problem, and we'd want to start at the `relu2` layer, not the `conv2` layer, like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = caffe.Net(model_def_file, pretrained_model)\n",
      "relu5 = net.ForwardFrom('relu2', 'relu5', saved_blobs['conv2'], shape_ref='conv5')\n",
      "print 'difference:', abs(saved_blobs['conv5'] - relu5).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Complete backward pass"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Define a few functions to show images\n",
      "def norm01(arr):\n",
      "    arr = arr.copy()\n",
      "    arr -= arr.min()\n",
      "    arr /= arr.max()\n",
      "    return arr\n",
      "\n",
      "def showimage(im):\n",
      "    if im.ndim == 3:\n",
      "        # switch order from c,0,1 -> 0,1,c\n",
      "        im = im.transpose((1,2,0))\n",
      "        # The network takes BGR images, so we need to switch color channels\n",
      "        im = im[:, :, ::-1]\n",
      "    plt.imshow(im)\n",
      "\n",
      "def showimagesc(im):\n",
      "    showimage(norm01(im))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a net and visualize the input"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = caffe.Net(model_def_file, pretrained_model)\n",
      "net.set_phase_test()\n",
      "\n",
      "data = imagenet.prepare_image(image_filename)\n",
      "softmax = empty((10, 1000, 1, 1), dtype=np.float32)\n",
      "\n",
      "_=showimagesc(data[4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, pass the data all the way up to get the activations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net.Forward([data], [softmax])\n",
      "\n",
      "figsize(12,4)\n",
      "plot(softmax[4].flatten())\n",
      "iimax = softmax[4].argmax()\n",
      "plot(iimax, softmax[4].flatten()[iimax], 'ro')\n",
      "_=title('Max at idx %d (%s)' % (iimax, labels[iimax]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Show the network with all `diffs = 0` before backward pass"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we can compute the gradient of the max detector w.r.t. the input pixels, and show this as an image in pixel space."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_diff = 0*data\n",
      "softmax_diff = 0*softmax\n",
      "softmax_diff[4,iimax,0,0] = 1.0\n",
      "net.Backward([softmax_diff], [data_diff])\n",
      "showimagesc(data_diff[4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also, we can see that all the layers now have diffs filled in:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Partial backward pass"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But what if we want to compute other partial derivatives, like $\\frac{\\partial \\mathrm{conv3}_i}{\\partial x_j}$ for some unit $i$ in the conv3 layer and some pixel $x_j$?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net = caffe.Net(model_def_file, pretrained_model)\n",
      "net.set_phase_test()\n",
      "\n",
      "data = imagenet.prepare_image(image_filename)\n",
      "softmax = empty((10, 1000, 1, 1), dtype=np.float32)\n",
      "data_diff = 0*data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, try full forward and back"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net.Forward([data], [softmax])\n",
      "\n",
      "iimax = softmax[4].argmax()\n",
      "softmax_diff = 0*softmax\n",
      "softmax_diff[4,iimax,0,0] = 1.0\n",
      "\n",
      "net.Backward([softmax_diff], [data_diff])\n",
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, full backward using `BackwardFrom`, which should produce the same diffs as above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clear diffs:\n",
      "net.Backward([0*softmax_diff], [data_diff])\n",
      "net.Forward([data], [softmax])\n",
      "\n",
      "iimax = softmax[4].argmax()\n",
      "softmax_diff = 0*softmax\n",
      "softmax_diff[4,iimax,0,0] = 1.0\n",
      "\n",
      "net.BackwardFrom('prob', 'data', softmax_diff)\n",
      "\n",
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, only go back to the conv2 layer using `BackwardFrom`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clear diffs:\n",
      "net.Backward([0*softmax_diff], [data_diff])\n",
      "net.Forward([data], [softmax])\n",
      "\n",
      "iimax = softmax[4].argmax()\n",
      "softmax_diff = 0*softmax\n",
      "softmax_diff[4,iimax,0,0] = 1.0\n",
      "\n",
      "net.BackwardFrom('prob', 'conv2', softmax_diff)\n",
      "\n",
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But that's barely useful except to save a little speed. The main use of `BackwardFrom` is starting somewhere in the middle of the network:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clear diffs:\n",
      "net.Backward([0*softmax_diff], [data_diff])\n",
      "net.Forward([data], [softmax])\n",
      "\n",
      "conv4 = net.blobs['conv4'].data\n",
      "iimax = conv4[4].argmax()\n",
      "conv4_diff = 0*conv4\n",
      "conv4_diff[4].flat[iimax] = 1.0\n",
      "\n",
      "net.BackwardFrom('conv4', 'conv2', conv4_diff)\n",
      "\n",
      "shownet(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Scratch"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_layer_info(name):\n",
      "    '''Returns the layer index and blob size'''\n",
      "    if name == 'data':\n",
      "        return 0, net.blobs['data'].data.shape\n",
      "    else:\n",
      "        names = [ll.name for ll in net.layers]\n",
      "        ret_idx = names.index(name) + 1   # + 1 because data is 0...\n",
      "        return net.blobs[net.layers[0].name].data.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%connect_info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net.complete_layers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}