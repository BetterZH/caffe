{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Response Normalization demos\n",
      "\n",
      "## Definitions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylab import *\n",
      "%matplotlib inline\n",
      "rcParams['figure.figsize'] = (14,6)\n",
      "plt.rcParams['image.interpolation'] = 'nearest'\n",
      "plt.rcParams['image.cmap'] = 'gray'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_lines(dat, color=None):\n",
      "    if color is None:\n",
      "        vlines(arange(len(dat)), 0*dat, dat)\n",
      "        plot(arange(len(dat)), dat, 'o')\n",
      "    else:\n",
      "        vlines(arange(len(dat)), 0*dat, dat, color=color)\n",
      "        plot(arange(len(dat)), dat, 'o', color=color, markeredgecolor=color)\n",
      "    axhline(color='k')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rnorm(dat, size, alpha, beta):\n",
      "    ret = 0.0*dat\n",
      "    assert len(dat.shape) == 1, 'dat should be a 1D vector'\n",
      "    assert isinstance(size, int), 'size should be an int'\n",
      "    alpha = float(alpha)\n",
      "    beta = float(beta)\n",
      "    S = len(dat)\n",
      "    \n",
      "    for ii in range(S):\n",
      "        #print 'ii =', ii\n",
      "        tmpsum = 0\n",
      "        jjregion = range(max(0, ii-size/2), min(S, ii-size/2+size))\n",
      "        N = len(jjregion)\n",
      "        for jj in jjregion:\n",
      "            #print '  jj =', jj\n",
      "            tmpsum += dat[jj]**2\n",
      "        ret[ii] = dat[ii] / (1 + alpha/N * tmpsum) ** beta\n",
      "\n",
      "    return ret"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = array([0, 0, -.5, .5, .2, .1, 2, 0, -.1, .1, .1, -3, 5, 3, -.5, -4, 5, -3, 0], dtype=float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Base Case"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Base case: `beta = .5`, `alpha = 1`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data, 'b')\n",
      "plot_lines(rnorm(data, size=5, alpha=1, beta=.5), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Effects of beta"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Beta controls the strength of the reduction: beta = 0 is no reduction, beta = .05 is weak reduction, beta = .95 is stronger."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data, 'b')\n",
      "plot_lines(rnorm(data, size=5, alpha=1, beta=0), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data, 'b')\n",
      "plot_lines(rnorm(data, size=5, alpha=1, beta=.05), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data, 'b')\n",
      "plot_lines(rnorm(data, size=5, alpha=1, beta=.95), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Beta greater than 1.0 (here we show 2.0) flips activation levels. It reduces areas of high activation to be *smaller* than areas of low activation. This is not used in practice."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data, 'b')\n",
      "plot_lines(rnorm(data, size=5, alpha=1, beta=2.0), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Effects of alpha"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll use beta = .75, which seems common. `Alpha` controls the scale above which the normalization kicks in. Normalization starts to affect those regions with values above ~1/alpha."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data, 'b')\n",
      "plot_lines(rnorm(data, size=5, alpha=1, beta=.75), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data*100, 'b')\n",
      "plot_lines(rnorm(data*100, size=5, alpha=(1.0/100)**2, beta=.75), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data, 'b')\n",
      "plot_lines(rnorm(data, size=5, alpha=1/(.5)**2, beta=.75), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data, 'b')\n",
      "plot_lines(rnorm(data, size=5, alpha=1/(4.0)**2, beta=.75), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data*100, 'b')\n",
      "plot_lines(rnorm(data*100, size=5, alpha=1/(400.0)**2, beta=.75), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Approximate normalization in a trained Caffe network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_lines(data*1000, 'b')\n",
      "plot_lines(rnorm(data*1000, size=5, alpha=1/(100.0)**2, beta=.75), 'r')\n",
      "\n",
      "# Just scaled up by 20 so detail is visible\n",
      "# hi\n",
      "plot_lines(rnorm(data*1000, size=5, alpha=1/(100.0)**2, beta=.75) * 20, 'm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or, normalized to the same scale:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d2 = data*1000\n",
      "rnorm_d2 = rnorm(d2, size=5, alpha=1/(100.0)**2, beta=.75)\n",
      "\n",
      "plot_lines(d2/d2.max(), 'b')\n",
      "plot_lines(rnorm_d2/rnorm_d2.max(), 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}