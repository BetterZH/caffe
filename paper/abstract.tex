% !TEX root = main.tex

A high percentage of deep neural networks trained on
natural images exhibit a curious aspect in common: they all learn
features similar to Gabor filters on the first layer. Such features
appear to be \emph{general}, as opposed to \emph{specific} for a
particular task. Because higher layers are difficult to visualize, not
as much is known about whether the are general or specific. In this
paper we experimentally quantify the generality of neurons on each
layer of a deep convolutional neural network trained on ImageNet. The experiments also reveal a
few unexpected insights. First, we find that transferability is
negatively affected by two distinct issues: (a) The higher the layer, the worse it transfers. This result, which is to be expected, occurs because higher-level layers are more specialized to their original task, which hurts performance on the new task. (b) Co-adaptation occurs during training at intermediate layers such that layers must be trained at the same time to maximize performance, even on the same data set, which is a novel finding. 
%In an
%example network , we demonstrate that either of
%these two issues may dominate, depending on whether features are
%transferred from the bottom, middle, or top of the network.  
We also
show how the benefits of transfer learning decrease as the similarity between the original task and the new task decreases, but how even transfer from dissimilar 
tasks can be better than using random features. Finally, a
new, surprising result is that initializing a network with transferred
features can improve generalization, even if those features are further fine-tuned during training on a new task. 
