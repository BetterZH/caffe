% !TEX root = main.tex

A high percentage of recently reported deep networks trained on
natural images exhibit a curious aspect in common: they all learn
features similar to gabor filters on the first layer. Such features
appear to be \emph{general}, as opposed to \emph{specific} for a
particular task. Because higher layers are difficult to visualize, not
as much is known about whether the are general or specific. In this
paper we experimentally quantify the generality of neurons on each
layer of a deep convolutional neural network and through this expose a
few surprising aspects. First, we find that transferability is
negatively affected by two distinct issues --- not only the expected
specialization of higher layer neurons to their original task at the
expense of the target task, but also optimization difficulties related
to splitting networks in the middle of co-adapted neurons. In an
example network trained on ImageNet, we demonstrate that either of
these two issues may dominate, depending on whether features are
transferred from the bottom, middle, or top of the network.  We also
show how the transferability gap grows as the distance between base
task and target task increases, but how even transfer from distant
tasks can be better than using random features. Finally, we show a
surprising result that initializing a network with transferred
features from almost any number of layers can produce a boost to
generalization that lingers even after fine-tuning to the target
dataset.








% Or, Jeff's version:

%A high percentage of deep neural networks trained on
%natural images exhibit a curious aspect in common: they all learn
%features similar to Gabor filters on the first layer. Such features
%appear to be \emph{general}, as opposed to \emph{specific} for a
%particular task. Because higher layers are difficult to visualize, not
%as much is known about whether the are general or specific. In this
%paper we experimentally quantify the generality of neurons on each
%layer of a deep convolutional neural network trained on ImageNet. The experiments also reveal a
%few unexpected insights. First, we find that transferability is
%negatively affected by two distinct issues: (a) The higher the layer, the worse it transfers. This result, which is to be expected, occurs because higher-level layers are more specialized to their original task, which hurts performance on the new task. (b) Co-adaptation occurs during training at intermediate layers such that layers must be trained at the same time to maximize performance, even on the same data set, which is a novel finding. 
%%In an
%%example network , we demonstrate that either of
%%these two issues may dominate, depending on whether features are
%%transferred from the bottom, middle, or top of the network.  
%We also
%show how the benefits of transfer learning decrease as the similarity between the original task and the new task decreases, but how even transfer from dissimilar 
%tasks can be better than using random features. Finally, a
%new, surprising result is that initializing a network with transferred
%features can improve generalization, even if those features are further fine-tuned during training on a new task. 
