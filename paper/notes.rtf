{\rtf1\ansi\ansicpg1252\cocoartf1187\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid1\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid2\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid3\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li2160\lin2160 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid101\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid201\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid202\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid301\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid302\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid4}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}}
\margl1440\margr1440\vieww20060\viewh16600\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\b\fs30 \cf0 Outline\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\b0\fs24 \cf0 \
\pard\tx220\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\pardirnatural
\ls1\ilvl0\cf0 {\listtext	\uc0\u8259 	}Intro\
\pard\tx940\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls1\ilvl1\cf0 {\listtext	\uc0\u8259 	}The state of the field (great progress recently)\
{\listtext	\uc0\u8259 	}It's kind of cool that some things work well but we dont' even quite understand why. (Side note: this is a bit of a departure from traditional ML, where we just push to improve performance. Now we have some stuff that works and want to study why)\
{\listtext	\uc0\u8259 	}To this end, we've done some experiments:\
{\listtext	\uc0\u8259 	}Experiment: How generic are features?\
\pard\tx1660\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li2160\fi-2160\pardirnatural
\ls1\ilvl2\cf0 {\listtext	\uc0\u8259 	}This is a tricky question to pose. What do we even mean? Generic or specific with respect to what?\
{\listtext	\uc0\u8259 	}See also Donahue's work\
{\listtext	\uc0\u8259 	}We defined generic as transferring to a set of classes outside the dataset.\
{\listtext	\uc0\u8259 	}We tried two splits\
{\listtext	\uc0\u8259 	}Key findings: <insert info from lisa email here. Update for second experiment.>\
\pard\tx940\tx1440\tx1680\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls1\ilvl1\cf0 {\listtext	\uc0\u8259 	}Speed notes on training on top of generic features.\
\pard\tx1660\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li2160\fi-2160\pardirnatural
\ls1\ilvl2\cf0 {\listtext	\uc0\u8259 	}Compare to DeCaf paper? Speed is actually faster than expected??\
\pard\tx940\tx1440\tx1680\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls1\ilvl1\cf0 {\listtext	\uc0\u8259 	}Experiment: overfit with dataset size\
\pard\tx1660\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li2160\fi-2160\pardirnatural
\ls1\ilvl2\cf0 {\listtext	\uc0\u8259 	}Couldn't really find much on this, surprisingly. Time to do the experiment!\
\pard\tx940\tx1440\tx1680\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls1\ilvl1\cf0 {\listtext	\uc0\u8259 	}Extra surprising result:\
\pard\tx1660\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li2160\fi-2160\pardirnatural
\ls1\ilvl2\cf0 {\listtext	\uc0\u8259 	}coadaptation of middle units!\
\pard\tx220\tx720\tx1120\tx1680\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\pardirnatural
\ls1\ilvl0\cf0 {\listtext	\uc0\u8259 	}Method details\
\pard\tx940\tx1440\tx1680\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls1\ilvl1\cf0 {\listtext	\uc0\u8259 	}\uc0\u8730  We went with the architecture as in Alex's paper. Even though better ones exist (i.e. 7x7 from Matt Zeiler), we thought we'd go with the architecture used by the largest number of people, so our results would be comparable and extensible and useful to the most researchers. We actually expect none of the qualitative results presented here to depend at all on small architecture tweaks, though this is only a hunch\
{\listtext	\uc0\u8259 	}\uc0\u8730  Concretely, here are the layer sizes, parameters, etc that we used (table here)\
{\listtext	\uc0\u8259 	}X Also, why not: here's a table of layer activation and weight sizes (with biases separately). We don't all need to work this out on paper separately. Note: this may be slightly different than Alex's due to LRN diffs.\
{\listtext	\uc0\u8259 	}\uc0\u8730  All code and parameter files are available online at github (URL removed for review)\
\pard\tx220\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\pardirnatural
\ls1\ilvl0\cf0 {\listtext	\uc0\u8259 	}Experiments and results\
\pard\tx940\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls1\ilvl1\cf0 {\listtext	\uc0\u8259 	}XXX Reduced Data\
\pard\tx1660\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li2160\fi-2160\pardirnatural
\ls1\ilvl2\cf0 {\listtext	\uc0\u8259 	}Here's how much we overfit.\
{\listtext	\uc0\u8259 	}Figure + table. In table include total dataset size (and in figure??)\
{\listtext	\uc0\u8259 	}One conclusion: can clearly see that even more data would be great!\
{\listtext	\uc0\u8259 	}Even with one training example per class we get 4x better than chance.\
\pard\tx940\tx1440\tx1680\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls1\ilvl1\cf0 {\listtext	\uc0\u8259 	}Main Transfer results\
\pard\tx1660\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li2160\fi-2160\pardirnatural
\ls1\ilvl2\cf0 {\listtext	\uc0\u8259 	}transfer falls off, not much\
{\listtext	\uc0\u8259 	}transfer fails for optimization reasons, not just for reasons of dataset mismatch\
{\listtext	\uc0\u8259 	}the dataset mismatch can actually help!\
\pard\tx940\tx1440\tx1680\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls1\ilvl1\cf0 {\listtext	\uc0\u8259 	}NatMan split\
\pard\tx1660\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li2160\fi-2160\pardirnatural
\ls1\ilvl2\cf0 {\listtext	\uc0\u8259 	}Show filters from base / Nat / man??\
\pard\tx220\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\pardirnatural
\ls1\ilvl0\cf0 {\listtext	\uc0\u8259 	}Discussion and Conclusions\
\pard\tx940\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls1\ilvl1\cf0 {\listtext	\uc0\u8259 	}Cool stuff! This means that one can copy the first 4 layers.\
\pard\tx560\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 \
TODO later, maybe\
\pard\tx220\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\pardirnatural
\ls2\ilvl0\cf0 {\listtext	\uc0\u8259 	}top5 error in addition to top1\
{\listtext	\uc0\u8259 	}Make sure reduced plot is made with 1300-2 run when finished\
\pard\tx560\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 \

\b\fs30 Cites\

\b0\fs24 \
\pard\tx220\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\pardirnatural
\ls3\ilvl0\cf0 {\listtext	\uc0\u8259 	}Zeiler, arXiv 2013, Visualizing and Understanding Convolutional Networks\
\pard\tx940\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls3\ilvl1\cf0 {\listtext	\uc0\u8259 	}ablation study in Table 3. Some weirdness about overfit, etc...\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\b\fs30 \cf0 Transfer Section
\b0\fs24 \
\
\pard\tx220\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\pardirnatural
\ls4\ilvl0\cf0 {\listtext	\uc0\u8259 	}Random dataset\
{\listtext	\uc0\u8259 	}Nat vs. man dataset\
\pard\tx940\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li1440\fi-1440\pardirnatural
\ls4\ilvl1\cf0 {\listtext	\uc0\u8259 	}449 vs 551\'85 see notebook\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 \
\
\
\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\b\fs30 \cf0 Overfitting Section\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\b0\fs24 \cf0 \
Krizhevsky:\
The size of our network made overfitting a significant problem, even with 1.2 million labeled training examples, so we used several effective techniques for preventing overfitting, which are described in Section 4.\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
}